// Definitions
//--------------------------------------------------------------------------------------------------

// TODO: delete
#pragma enable_d3d11_debug_symbols
#pragma only_renderers d3d11 playstation xboxone xboxseries vulkan metal switch

#pragma kernel ScreenSpaceReflectionsTracing                                                SSR_TRACE
#pragma kernel ScreenSpaceReflectionsReprojection                                           SSR_REPROJECT



#pragma multi_compile _ DEPTH_SOURCE_NOT_FROM_MIP_CHAIN
#pragma multi_compile _ SSR_APPROX
#pragma multi_compile _ _GBUFFER_NORMALS_OCT

// Tweak parameters.
// #define DEBUG
#define SSR_TRACE_BEHIND_OBJECTS
#define SSR_TRACE_TOWARDS_EYE
#ifndef SSR_APPROX
    #define SAMPLES_VNDF
#endif
#define SSR_TRACE_EPS               0.000488281f // 2^-11, should be good up to 4K
#define MIN_GGX_ROUGHNESS           0.00001f
#define MAX_GGX_ROUGHNESS           0.99999f

//--------------------------------------------------------------------------------------------------
// Included headers
//--------------------------------------------------------------------------------------------------

#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/Common.hlsl"
#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/Packing.hlsl"
#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/Color.hlsl"

#include "Packages/com.unity.render-pipelines.danbaidong/ShaderLibrary/Core.hlsl"
#include "Packages/com.unity.render-pipelines.danbaidong/ShaderLibrary/UnityGBuffer.hlsl"
#include "Packages/com.unity.render-pipelines.danbaidong/Shaders/ScreenSpaceLighting/ScreenSpaceLighting.hlsl"

//--------------------------------------------------------------------------------------------------
// Inputs & outputs
//--------------------------------------------------------------------------------------------------

// For opaque we do the following operation:
// - Render opaque object in depth buffer
// - Generate depth pyramid from opaque depth buffer
// - Trigger ray from position recover from depth pyramid and raymarch with depth pyramid
// For transparent reflection we chose to not regenerate a depth pyramid to save performance. So we have
// - Generate depth pyramid from opaque depth buffer
// - Trigger ray from position recover from depth buffer (use depth pyramid) and raymarch with depth pyramid
// - Render transparent object with reflection in depth buffer in transparent prepass
// - Trigger ray from position recover from new depth buffer and raymarch with opaque depth pyramid
// So we need a seperate texture for the mip chain and for the depth source when doing the transprent reflection

TEXTURE2D_X(_CameraDepthTexture);
TEXTURE2D_X(_ColorPyramidTexture);
SAMPLER(ssr_trilinear_clamp_sampler);

TEXTURE2D(_CameraDepthBufferMipChain);
StructuredBuffer<int2>  _DepthPyramidMipLevelOffsets;

TEXTURE2D_X_HALF(_GBuffer2);

TEXTURE2D(_STBNTexture);

#ifdef SSR_TRACE
    Texture2D<uint2> _StencilTexture;
    RW_TEXTURE2D(float2, _SSRHitPointTexture);
#elif defined(SSR_REPROJECT)
       TEXTURE2D(        _SSRHitPointTexture);
    RW_TEXTURE2D(float4, _SSRAccumTexture);
#else //if defined(SSR_ACCUMULATE)
       TEXTURE2D(        _SSRHitPointTexture);
    RW_TEXTURE2D(float4, _SsrAccumPrev);
    RW_TEXTURE2D(float4, _SsrLightingTextureRW);
    RW_TEXTURE2D(float4, _SSRAccumTexture);
#endif

float4x4 _SSR_MATRIX_VP;
float4x4 _SSR_MATRIX_I_VP;

float _SsrThicknessScale;
float _SsrThicknessBias;
// int _SsrStencilBit;
int _SsrIterLimit;
float _SsrRoughnessFadeEnd;
float _SsrRoughnessFadeRcpLength;
float _SsrRoughnessFadeEndTimesRcpLength;
float _SsrEdgeFadeRcpLength;
// float4 _ColorPyramidUvScaleAndLimitPrevFrame;
int _SsrDepthPyramidMaxMip;
int _SsrColorPyramidMaxMip;
int _SsrReflectsSky;
// float _SsrAccumulationAmount;
// float _SsrPBRSpeedRejection;
float _SsrPBRBias;
// float _SsrPRBSpeedRejectionScalerFactor;
// float _SsrPBRPad0;

//--------------------------------------------------------------------------------------------------
// Helpers
//--------------------------------------------------------------------------------------------------

float PerceptualRoughnessFade(float perceptualRoughness, float fadeRcpLength, float fadeEndTimesRcpLength)
{
    float t = Remap10(perceptualRoughness, fadeRcpLength, fadeEndTimesRcpLength);
    return Smoothstep01(t);
}

void GetNormalAndPerceptualRoughness(uint2 positionSS, out float3 normalWS, out float perceptualRoughness)
{
    // Load normal and perceptualRoughness.
    half4 normalGBuffer = LOAD_TEXTURE2D_X(_GBuffer2, positionSS);
    
    normalWS = normalize(UnpackNormal(normalGBuffer.xyz)); // normalize() is required because terrain shaders use additive blending for normals (not unit-length anymore)
    perceptualRoughness = PerceptualSmoothnessToPerceptualRoughness(normalGBuffer.a);
}

//--------------------------------------------------------------------------------------------------
// Implementation
//--------------------------------------------------------------------------------------------------

#ifdef SSR_TRACE
[numthreads(8, 8, 1)]
void ScreenSpaceReflectionsTracing(uint3 dispatchThreadId : SV_DispatchThreadID)
{
    uint2 positionSS = dispatchThreadId.xy;

    // Stencil check off
    // bool doesntReceiveSSR = false;
    // uint stencilValue = GetStencilValue(LOAD_TEXTURE2D(_StencilTexture, positionSS));

    float  deviceDepth = LOAD_TEXTURE2D(_CameraDepthTexture, positionSS).r;

#ifdef SSR_APPROX
    float2 positionNDC = positionSS * _ScreenSize.zw + (0.5 * _ScreenSize.zw);
    float3 positionWS = ComputeWorldSpacePosition(positionNDC, deviceDepth, _SSR_MATRIX_I_VP); // Jittered
    float3 V = GetWorldSpaceNormalizeViewDir(positionWS);

    float3 N;
    float perceptualRoughness;
    GetNormalAndPerceptualRoughness(positionSS, N, perceptualRoughness);

    float3 R = reflect(-V, N);
#else
    // PBR
    float2 positionNDC = positionSS * _ScreenSize.zw + (0.5 * _ScreenSize.zw);
    float3 positionWS = ComputeWorldSpacePosition(positionNDC, deviceDepth, _SSR_MATRIX_I_VP); // Jittered
    float3 V = GetWorldSpaceNormalizeViewDir(positionWS);

    float3 N;
    float perceptualRoughness;
    GetNormalAndPerceptualRoughness(positionSS, N, perceptualRoughness);
    

    float2 blueNoiseRandom = 0;
    blueNoiseRandom.xy = _STBNTexture[float2(positionSS.x % 128, positionSS.y % 128)].xy;
    // Bias will make the sampled points cluster more towards the top of the hemisphere.
    blueNoiseRandom.x = lerp(blueNoiseRandom.x, 0.0f, _SsrPBRBias);

    float3 R = reflect(-V, N);

    float NdotL, NdotH, VdotH, NdotV;
    float3x3 localToWorld = GetLocalFrame(N);
    float roughness = PerceptualRoughnessToRoughness(perceptualRoughness);
    SampleGGXDir(blueNoiseRandom, V, localToWorld, roughness, R, NdotL, NdotH, VdotH);

    NdotV = dot(N, V);
    float Vg = V_SmithJointGGX(NdotL, NdotV, roughness);

    float weight = 4.0f * NdotL * VdotH * Vg / NdotH;

    if (NdotL < 0.001f || weight < 0.001f)
    {
        return;
    }
#endif /* SSR_PBR */

    float3 camPosWS = GetCurrentViewPosition();
    
    // Apply normal bias with the magnitude dependent on the distance from the camera.
    // Unfortunately, we only have access to the shading normal, which is less than ideal...
    positionWS = camPosWS + (positionWS - camPosWS) * (1 - 0.001 * rcp(max(dot(N, V), FLT_EPS)));
    deviceDepth = ComputeNormalizedDeviceCoordinatesWithZ(positionWS, _SSR_MATRIX_VP).z;
    bool killRay = deviceDepth == UNITY_RAW_FAR_CLIP_VALUE;

    // Ref. #1: Michal Drobot - Quadtree Displacement Mapping with Height Blending.
    // Ref. #2: Yasin Uludag  - Hi-Z Screen-Space Cone-Traced Reflections.
    // Ref. #3: Jean-Philippe Grenier - Notes On Screen Space HIZ Tracing.
    // Warning: virtually all of the code below assumes reverse Z.

    // We start tracing from the center of the current pixel, and do so up to the far plane.
    float3 rayOrigin = float3(positionSS + 0.5, deviceDepth);

    float3 reflPosWS  = positionWS + R;
    float3 reflPosNDC = ComputeNormalizedDeviceCoordinatesWithZ(reflPosWS, _SSR_MATRIX_VP); // Jittered
    float3 reflPosSS  = float3(reflPosNDC.xy * _ScreenSize.xy, reflPosNDC.z);
    float3 rayDir     = reflPosSS - rayOrigin;
    float3 rcpRayDir  = rcp(rayDir);
    int2   rayStep    = int2(rcpRayDir.x >= 0 ? 1 : 0,
                             rcpRayDir.y >= 0 ? 1 : 0);
    float3 raySign  = float3(rcpRayDir.x >= 0 ? 1 : -1,
                             rcpRayDir.y >= 0 ? 1 : -1,
                             rcpRayDir.z >= 0 ? 1 : -1);
    bool   rayTowardsEye  =  rcpRayDir.z >= 0;
    
    // Note that we don't need to store or read the perceptualRoughness value
    // if we mark stencil during the G-Buffer pass with pixels which should receive SSR,
    // and sample the color pyramid during the lighting pass.
    killRay = killRay || (reflPosSS.z <= 0);
    killRay = killRay || (dot(N, V) <= 0);
    killRay = killRay || (perceptualRoughness > _SsrRoughnessFadeEnd);
#ifndef SSR_TRACE_TOWARDS_EYE
    killRay = killRay || rayTowardsEye;
#endif

    if (killRay)
    {
        return;
    }

    // Extend and clip the end point to the frustum.
    float tMax;
    {
        // Shrink the frustum by half a texel for efficiency reasons.
        const float halfTexel = 0.5;

        float3 bounds;
        bounds.x = (rcpRayDir.x >= 0) ? _ScreenSize.x - halfTexel : halfTexel;
        bounds.y = (rcpRayDir.y >= 0) ? _ScreenSize.y - halfTexel : halfTexel;
        // If we do not want to intersect the skybox, it is more efficient to not trace too far.
        float maxDepth = (_SsrReflectsSky != 0) ? -0.00000024 : 0.00000024; // 2^-22
        bounds.z = (rcpRayDir.z >= 0) ? 1 : maxDepth;

        float3 dist = bounds * rcpRayDir - (rayOrigin * rcpRayDir);
        tMax = Min3(dist.x, dist.y, dist.z);
    }

    // Clamp the MIP level to give the compiler more information to optimize.
    const int maxMipLevel = min(_SsrDepthPyramidMaxMip, 14);

    // Start ray marching from the next texel to avoid self-intersections.
    float t;
    {
        // 'rayOrigin' is the exact texel center.
        float2 dist = abs(0.5 * rcpRayDir.xy);
        t = min(dist.x, dist.y);
    }

    float3 rayPos;

    int  mipLevel  = 0;
    int  iterCount = 0;
    bool hit       = false;
    bool miss      = false;
    bool belowMip0 = false; // This value is set prior to entering the cell


    while (!(hit || miss) && (t <= tMax) && (iterCount < _SsrIterLimit))
    {
        rayPos = rayOrigin + t * rayDir;

        // Ray position often ends up on the edge. To determine (and look up) the right cell,
        // we need to bias the position by a small epsilon in the direction of the ray.
        float2 sgnEdgeDist = round(rayPos.xy) - rayPos.xy;
        float2 satEdgeDist = clamp(raySign.xy * sgnEdgeDist + SSR_TRACE_EPS, 0, SSR_TRACE_EPS);
        rayPos.xy += raySign.xy * satEdgeDist;

        int2 mipCoord  = (int2)rayPos.xy >> mipLevel;
        int2 mipOffset = _DepthPyramidMipLevelOffsets[mipLevel];
        // Bounds define 4 faces of a cube:
        // 2 walls in front of the ray, and a floor and a base below it.
        float4 bounds;

        bounds.xy = (mipCoord + rayStep) << mipLevel;
        bounds.z  = LOAD_TEXTURE2D_X(_CameraDepthBufferMipChain, mipOffset + mipCoord).r;

        // We define the depth of the base as the depth value as:
        // b = DeviceDepth((1 + thickness) * LinearDepth(d))
        // b = ((f - n) * d + n * (1 - (1 + thickness))) / ((f - n) * (1 + thickness))
        // b = ((f - n) * d - n * thickness) / ((f - n) * (1 + thickness))
        // b = d / (1 + thickness) - n / (f - n) * (thickness / (1 + thickness))
        // b = d * k_s + k_b
        bounds.w = bounds.z * _SsrThicknessScale + _SsrThicknessBias;

        float4 dist      = bounds * rcpRayDir.xyzz - (rayOrigin.xyzz * rcpRayDir.xyzz);
        float  distWall  = min(dist.x, dist.y);
        float  distFloor = dist.z;
        float  distBase  = dist.w;

        // Note: 'rayPos' given by 't' can correspond to one of several depth values:
        // - above or exactly on the floor
        // - inside the floor (between the floor and the base)
        // - below the base
    #if 0
        bool belowFloor  = (raySign.z * (t - distFloor)) <  0;
        bool aboveBase   = (raySign.z * (t - distBase )) >= 0;
    #else
        bool belowFloor  = rayPos.z  < bounds.z;
        bool aboveBase   = rayPos.z >= bounds.w;
    #endif
        bool insideFloor = belowFloor && aboveBase;
        bool hitFloor    = (t <= distFloor) && (distFloor <= distWall);

        // Game rules:
        // * if the closest intersection is with the wall of the cell, switch to the coarser MIP, and advance the ray.
        // * if the closest intersection is with the heightmap below,  switch to the finer   MIP, and advance the ray.
        // * if the closest intersection is with the heightmap above,  switch to the finer   MIP, and do NOT advance the ray.
        // Victory conditions:
        // * See below. Do NOT reorder the statements!

    #ifdef SSR_TRACE_BEHIND_OBJECTS
        miss      = belowMip0 && insideFloor;
    #else
        miss      = belowMip0;
    #endif
        hit       = (mipLevel == 0) && (hitFloor || insideFloor);
        belowMip0 = (mipLevel == 0) && belowFloor;

        // 'distFloor' can be smaller than the current distance 't'.
        // We can also safely ignore 'distBase'.
        // If we hit the floor, it's always safe to jump there.
        // If we are at (mipLevel != 0) and we are below the floor, we should not move.
        t = hitFloor ? distFloor : (((mipLevel != 0) && belowFloor) ? t : distWall);
        rayPos.z = bounds.z; // Retain the depth of the potential intersection

        // Warning: both rays towards the eye, and tracing behind objects has linear
        // rather than logarithmic complexity! This is due to the fact that we only store
        // the maximum value of depth, and not the min-max.
        mipLevel += (hitFloor || belowFloor || rayTowardsEye) ? -1 : 1;
        mipLevel  = clamp(mipLevel, 0, maxMipLevel);

        // mipLevel = 0;

        iterCount++;
    }

    // Treat intersections with the sky as misses.
    miss = miss || ((_SsrReflectsSky == 0) && (rayPos.z == 0));
    hit  = hit && !miss;

    if (hit)
    {
        // Note that we are using 'rayPos' from the penultimate iteration, rather than
        // recompute it using the last value of 't', which would result in an overshoot.
        // It also needs to be precisely at the center of the pixel to avoid artifacts.
        float2 hitPositionNDC = floor(rayPos.xy) * _ScreenSize.zw + (0.5 * _ScreenSize.zw); // Should we precompute the half-texel bias? We seem to use it a lot.
        _SSRHitPointTexture[positionSS] = hitPositionNDC.xy;
    }
    
}

#elif defined(SSR_REPROJECT)

[numthreads(8, 8, 1)]
void ScreenSpaceReflectionsReprojection(uint3 dispatchThreadId : SV_DispatchThreadID)
{
    const uint2 positionSS = dispatchThreadId.xy;

    float3 N;
    float perceptualRoughness;
    GetNormalAndPerceptualRoughness(positionSS, N, perceptualRoughness);

    // Compute the actual roughness
    float roughness = PerceptualRoughnessToRoughness(perceptualRoughness);
    roughness = clamp(roughness, MIN_GGX_ROUGHNESS, MAX_GGX_ROUGHNESS);

    float2 hitPositionNDC = LOAD_TEXTURE2D_X(_SSRHitPointTexture, positionSS).xy;

    if (max(hitPositionNDC.x, hitPositionNDC.y) == 0)
    {
        // Miss.
        return;
    }

    // TODO: MotionVector

    // TODO: filtering is quite awful. Needs to be non-Gaussian, bilateral and anisotropic.
    float  mipLevel = lerp(0, _SsrColorPyramidMaxMip, perceptualRoughness);


    float opacity = EdgeOfScreenFade(hitPositionNDC, _SsrEdgeFadeRcpLength)
                  * PerceptualRoughnessFade(perceptualRoughness, _SsrRoughnessFadeRcpLength, _SsrRoughnessFadeEndTimesRcpLength);

#ifdef SSR_APPROX
    // Note that the color pyramid uses it's own viewport scale, since it lives on the camera.
    float3 color   = SAMPLE_TEXTURE2D_X_LOD(_ColorPyramidTexture, ssr_trilinear_clamp_sampler, hitPositionNDC, mipLevel).rgb;

    // Disable SSR for negative, infinite and NaN history values.
    uint3 intCol   = asuint(color);
    bool  isPosFin = Max3(intCol.r, intCol.g, intCol.b) < 0x7F800000;

    color   = isPosFin ? color   : 0;
    opacity = isPosFin ? opacity : 0;


    _SSRAccumTexture[positionSS] = float4(color, 1.0f) * opacity;
#else
    // PBR Accum

    // Note that the color pyramid uses it's own viewport scale, since it lives on the camera.
    float3 color   = SAMPLE_TEXTURE2D_X_LOD(_ColorPyramidTexture, ssr_trilinear_clamp_sampler, hitPositionNDC, mipLevel).rgb;

    // Disable SSR for negative, infinite and NaN history values.
    uint3 intCol   = asuint(color);
    bool  isPosFin = Max3(intCol.r, intCol.g, intCol.b) < 0x7F800000;

    color   = isPosFin ? color   : 0;
    opacity = isPosFin ? opacity : 0;


    _SSRAccumTexture[positionSS] = float4(color, 1.0f) * opacity;
#endif

}

#elif defined(SSR_ACCUMULATE)

#endif

#undef MIN_GGX_ROUGHNESS
#undef MAX_GGX_ROUGHNESS