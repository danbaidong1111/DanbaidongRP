// Definitions
//--------------------------------------------------------------------------------------------------

// TODO: delete
// #pragma enable_d3d11_debug_symbols
#pragma only_renderers d3d11 playstation xboxone xboxseries vulkan metal switch

#pragma kernel ScreenSpaceReflectionsClassifyTiles                                          SSR_CLASSIFYTILES
#pragma kernel ScreenSpaceReflectionsTracing                                                SSR_TRACE
#pragma kernel ScreenSpaceReflectionsResolve                                                SSR_RESOLVE
#pragma kernel ScreenSpaceReflectionsAccumulate                                             SSR_ACCUMULATE

#pragma multi_compile _ SSR_APPROX
#pragma multi_compile _ _GBUFFER_NORMALS_OCT

// Tweak parameters.
#define SSR_TRACE_BEHIND_OBJECTS
#define SSR_TRACE_TOWARDS_EYE

#define SSR_TRACE_EPS               0.000488281f // 2^-11, should be good up to 4K
#define MIN_GGX_ROUGHNESS           0.00001f
#define MAX_GGX_ROUGHNESS           0.99999f
//--------------------------------------------------------------------------------------------------
// Included headers
//--------------------------------------------------------------------------------------------------

#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/Common.hlsl"
#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/Packing.hlsl"
#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/Color.hlsl"

#include "Packages/com.unity.render-pipelines.danbaidong/ShaderLibrary/Core.hlsl"
#include "Packages/com.unity.render-pipelines.danbaidong/ShaderLibrary/UnityGBuffer.hlsl"
#include "Packages/com.unity.render-pipelines.danbaidong/Shaders/ScreenSpaceLighting/ScreenSpaceLighting.hlsl"
#include "Packages/com.unity.render-pipelines.danbaidong/Runtime/ScreenSpaceLighting/ShaderVariablesScreenSpaceReflection.cs.hlsl"

//--------------------------------------------------------------------------------------------------
// Inputs & outputs
//--------------------------------------------------------------------------------------------------

// For opaque we do the following operation:
// - Render opaque object in depth buffer
// - Generate depth pyramid from opaque depth buffer
// - Trigger ray from position recover from depth pyramid and raymarch with depth pyramid
// For transparent reflection we chose to not regenerate a depth pyramid to save performance. So we have
// - Generate depth pyramid from opaque depth buffer
// - Trigger ray from position recover from depth buffer (use depth pyramid) and raymarch with depth pyramid
// - Render transparent object with reflection in depth buffer in transparent prepass
// - Trigger ray from position recover from new depth buffer and raymarch with opaque depth pyramid
// So we need a seperate texture for the mip chain and for the depth source when doing the transprent reflection

TEXTURE2D_X_FLOAT(_CameraDepthTexture);
SAMPLER(sampler_CameraDepthTexture);
TEXTURE2D_X(_ColorPyramidTexture);
SAMPLER(ssr_trilinear_clamp_sampler);
SAMPLER(ssr_bilinear_clamp_sampler);
SAMPLER(ssr_point_clamp_sampler);

TEXTURE2D(_CameraDepthBufferMipChain);
StructuredBuffer<int2>  _DepthPyramidMipLevelOffsets;

TEXTURE2D_X_FLOAT(_GBuffer2);


#define TILE_INDEX_MASK (0xffffu)
#define TILE_INDEX_SHIFT_X (0)
#define TILE_INDEX_SHIFT_Y (16)

RWBuffer<uint> gDispatchIndirectBuffer;
RWStructuredBuffer<uint> gTileList;


#ifdef SSR_CLASSIFYTILES

#elif defined(SSR_TRACE)
    RW_TEXTURE2D(float2, _SSRHitPointTexture);
    RW_TEXTURE2D(float2, _SSRRayInfoTexture);
#elif defined(SSR_RESOLVE)
       TEXTURE2D(        _SSRHitPointTexture);
    TEXTURE2D(_SSRRayInfoTexture);
    RW_TEXTURE2D(float,  _SSRHitDepthTexture);
    RW_TEXTURE2D(float,  _SSRResolveVarianceTexture);
    RW_TEXTURE2D(float4, _SSRAccumTexture);
    RW_TEXTURE2D(float3, _SSRAvgRadianceTexture);
#elif defined(SSR_ACCUMULATE)
       TEXTURE2D(        _SSRHitPointTexture);
       TEXTURE2D(        _SSRHitDepthTexture);
       TEXTURE2D(        _SSRResolveVarianceTexture);
       TEXTURE2D(        _SsrAccumPrev);
       TEXTURE2D(        _SSRAvgRadianceTexture);
       TEXTURE2D(        _SSRPrevNumFramesAccumTexture);
    // RW_TEXTURE2D(float4, _SsrAccumPrev);
    RW_TEXTURE2D(float4, _SsrLightingTexture);
    RW_TEXTURE2D(float4, _SSRAccumTexture);
    RW_TEXTURE2D(float,  _SSRNumFramesAccumTexture);
#elif defined(SSR_BILATERAL)
       TEXTURE2D(        _SSRResolveVarianceTexture);
    RW_TEXTURE2D(float4, _SSRAccumTexture);
    RW_TEXTURE2D(float4, _SsrLightingTexture);
#elif defined(SSR_ATROUS)
    RW_TEXTURE2D(float4, _SSRAccumTexture);
#endif

// Use constant buffer instead
// float4x4 _SSR_MATRIX_VP;
// float4x4 _SSR_MATRIX_I_VP;

// float4x4 _SSR_PREV_MATRIX_VP;
// float4x4 _SSR_MATRIX_CLIP_TO_PREV_CLIP;

// float4 _SsrTraceScreenSize;
// float _SsrThicknessScale;
// float _SsrThicknessBias;
// int _SsrIterLimit;
// float _SsrRoughnessFadeEnd;
// float _SsrRoughnessFadeRcpLength;
// float _SsrRoughnessFadeEndTimesRcpLength;
// float _SsrEdgeFadeRcpLength;
// float4 _ColorPyramidUvScaleAndLimitPrevFrame;
// int _SsrDepthPyramidMaxMip;
// int _SsrColorPyramidMaxMip;
// int _SsrReflectsSky;
// float _SsrAccumulationAmount;
// float _SsrPBRBias;
// float _SsrFrameCount;
// float4 _HistoryFrameRTSize; // width height 1/width 1/height

//--------------------------------------------------------------------------------------------------
// Helpers
//--------------------------------------------------------------------------------------------------

#define NEED_RAYTRACED_REFLECTIONS(perceptualRoughness) (perceptualRoughness < _SsrRoughnessFadeEnd)
#define IS_MIRROR_REFLECTIONS(perceptualRoughness) (perceptualRoughness < 0.01)

uint2 DecodeTileIndex(uint encoded)
{
    return uint2((encoded >> TILE_INDEX_SHIFT_X) & TILE_INDEX_MASK, (encoded >> TILE_INDEX_SHIFT_Y) & TILE_INDEX_MASK);
}

uint EncodeTileIndex(uint2 tileID)
{
    return (tileID.y << TILE_INDEX_SHIFT_Y) | (tileID.x << TILE_INDEX_SHIFT_X);
}

void InitializeDispatchThreadIdFromTileList(uint groupId, uint2 gThreadId, out uint2 dThreadId)
{
    uint  encodedTileIndex = gTileList[groupId];
    uint2 tileCoord = DecodeTileIndex(encodedTileIndex);
    dThreadId = tileCoord + gThreadId.xy;
}

float2 TransformCoordSSToScreenUV(uint2 coordSS, float4 screenSize)
{
    return coordSS * screenSize.zw + (0.5 * screenSize.zw);
}

uint2 TransformScreenUVToCoordSS(float2 screenUV, float4 screenSize)
{
    uint2 coordSS = screenUV / screenSize.zw;
    coordSS = floor(coordSS);
    return coordSS;
}

// Weight for SSR where Fresnel == 1
float GetSSRSampleWeight(float NdotV, float NdotL, float roughness)
{
    // Importance sampling weight for each sample:
    // pdf = G1(V) * D(H) / (4 * (N.V));
    // weight = fr * (N.L) with fr = F(H) * G2(V, L) * D(H) / (4 * (N.L) * (N.V))
    // weight over pdf is:
    // weightOverPdf = F(H) * G2(V, L) / G1(V)
    // F is apply outside the function

    // V = G / (4 * NdotL * NdotV)
    float G2 = V_SmithJointGGX(NdotL, NdotV, roughness) * 4 * NdotL * NdotV;
    float G1 = G_MaskingSmithGGX(NdotV, roughness);

    return G2 / G1;
}

float PerceptualRoughnessFade(float perceptualRoughness, float fadeRcpLength, float fadeEndTimesRcpLength)
{
    float t = Remap10(perceptualRoughness, fadeRcpLength, fadeEndTimesRcpLength);
    return Smoothstep01(t);
}

void GetNormalAndPerceptualRoughness(uint2 coordSS, out float3 normalWS, out float perceptualRoughness)
{
    // Load normal and perceptualRoughness.
    float4 normalGBuffer = LOAD_TEXTURE2D_X(_GBuffer2, coordSS);
    
    normalWS = normalize(DecodeNormal(normalGBuffer.xyz)); // normalize() is required because terrain shaders use additive blending for normals (not unit-length anymore)
    perceptualRoughness = PerceptualSmoothnessToPerceptualRoughness(normalGBuffer.a);
}

void SampleNormalAndPerceptualRoughness(float2 screenUV, out float3 normalWS, out float perceptualRoughness)
{
    // Load normal and perceptualRoughness.
    float4 normalGBuffer = SAMPLE_TEXTURE2D_X_LOD(_GBuffer2, ssr_point_clamp_sampler, screenUV, 0);
    
    normalWS = normalize(DecodeNormal(normalGBuffer.xyz)); // normalize() is required because terrain shaders use additive blending for normals (not unit-length anymore)
    perceptualRoughness = PerceptualSmoothnessToPerceptualRoughness(normalGBuffer.a);
}

float3 SampleRadianceFromPrevColorPyramid(float2 hitScreenUV)
{
    float3 radiance = 0;

    float  mipLevel = 0;
    // MotionVector, colorPyramid is from last frame.
    float2 motionVectorOff = SampleMotionVectorOffset(hitScreenUV, _ScreenSize);
    float2 prevFrameNDC = hitScreenUV - motionVectorOff;
    float2 prevFrameUV = prevFrameNDC * _ColorPyramidUvScaleAndLimitPrevFrame.xy;

    radiance = SAMPLE_TEXTURE2D_X_LOD(_ColorPyramidTexture, ssr_trilinear_clamp_sampler, prevFrameUV, mipLevel).rgb;

    return radiance;
}

float3 LoadUVAndSampleRadianceFromPrevColorPyramid(float2 hitScreenUV)
{
    float3 radiance = 0;

    // MotionVector, colorPyramid is from last frame.
    // TODO: resolve motion vector reprojection error
    float2 motionVectorOff = LoadMotionVectorOffset(TransformScreenUVToCoordSS(hitScreenUV, _ScreenSize));
    float2 prevFrameNDC = hitScreenUV - motionVectorOff;
    float2 prevFrameUV = prevFrameNDC * _ColorPyramidUvScaleAndLimitPrevFrame.xy;

    // mipLevel is 0 so we use bilinear
    radiance = SAMPLE_TEXTURE2D_X_LOD(_ColorPyramidTexture, ssr_bilinear_clamp_sampler, prevFrameUV, 0).rgb;

    return radiance;
}

float3 LoadUVAndSampleRadianceFromPrevColorPyramidWithOpacity(float2 hitScreenUV)
{
    float3 radiance = 0;

    // MotionVector, colorPyramid is from last frame.
    // TODO: resolve motion vector reprojection error
    float2 motionVectorOff = LoadMotionVectorOffset(TransformScreenUVToCoordSS(hitScreenUV, _ScreenSize));
    float2 prevFrameNDC = hitScreenUV - motionVectorOff;
    float2 prevFrameUV = prevFrameNDC * _ColorPyramidUvScaleAndLimitPrevFrame.xy;

    // mipLevel is 0 so we use bilinear
    radiance = SAMPLE_TEXTURE2D_X_LOD(_ColorPyramidTexture, ssr_bilinear_clamp_sampler, prevFrameUV, 0).rgb;

    float edgeOpacity = EdgeOfScreenFade(prevFrameNDC, _SsrEdgeFadeRcpLength);
    return radiance * edgeOpacity;
}

//https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Weighted_incremental_algorithm
void IncreaseVariance(float weight, float x, inout float weightSum, inout float mean, inout float varianceSum)
{
    weightSum += weight;
    float meanOld = mean;
    mean += (weight / weightSum) * (x - meanOld);
    varianceSum += weight * (x - meanOld) * (x - mean);
}

// See LinearEyeDepth()
// zBufferParam = { (f-n)/n, 1, (f-n)/n*f, 1/f }
float LinearDepthToDeviceZ(float linearDepth, float4 zBufferParam)
{
    return ((1.0 / linearDepth) - zBufferParam.w) / zBufferParam.z;
}


float CalculateLocalBrdfWeight(float3 N, float3 V, float3 L, float roughness)
{
    float3 H = normalize(V + L);
    float NdotH = dot(N, H);
    float NdotL = dot(N, L);
    float NdotV = dot(N, V);

    return DV_SmithJointGGX(NdotH, saturate(NdotL), ClampNdotV(NdotV), roughness);
}





//--------------------------------------------------------------------------------------------------
// Implementation
//--------------------------------------------------------------------------------------------------

#ifdef SSR_CLASSIFYTILES

groupshared uint gTileCount = 0;



[numthreads(8, 8, 1)]
void ScreenSpaceReflectionsClassifyTiles(uint3 dispatchThreadId : SV_DispatchThreadID, uint2 groupThreadId : SV_GroupThreadID)
{
    uint2 coordSS = dispatchThreadId.xy;
    float3 N;
    float perceptualRoughness;

    // Dispatch 0,0 initialize gDispatchIndirectBuffer (0,1,1).
    if ((dispatchThreadId.x == 0) && (dispatchThreadId.y == 0))
    {
        gDispatchIndirectBuffer[0] = 0;
        gDispatchIndirectBuffer[1] = 1;
        gDispatchIndirectBuffer[2] = 1;
    }

    // Disable offscreen pixels
    float2 coordSSFloat = float2(coordSS);
    bool needsRay = !(coordSSFloat.x >= _ScreenSize.x || coordSSFloat.y >= _ScreenSize.y);

    // Don't shoot a ray on very rough surfaces depends on _SsrRoughnessFadeEnd.
    GetNormalAndPerceptualRoughness(coordSS, N, perceptualRoughness);
    needsRay = needsRay && NEED_RAYTRACED_REFLECTIONS(perceptualRoughness);

    // Don't shoot a ray on sky.
    float  deviceDepth = LOAD_TEXTURE2D_X(_CameraDepthTexture, coordSS).r;
    needsRay = needsRay && !(deviceDepth == UNITY_RAW_FAR_CLIP_VALUE);



    if (needsRay)
    {
        InterlockedAdd(gTileCount, 1);
    }

    GroupMemoryBarrierWithGroupSync();


    if ((groupThreadId.x == 0) && (groupThreadId.y == 0) && (gTileCount > 0))
    {
        uint tileOffset = 0;
        InterlockedAdd(gDispatchIndirectBuffer[0], 1, tileOffset);
        gTileList[tileOffset] = EncodeTileIndex(dispatchThreadId.xy);


    }
}








#elif SSR_TRACE
[numthreads(8, 8, 1)]
void ScreenSpaceReflectionsTracing(uint3 dispatchThreadId : SV_DispatchThreadID, uint2 groupThreadId : SV_GroupThreadID, uint groupId : SV_GroupID)
{
    uint2 coordSS;
    InitializeDispatchThreadIdFromTileList(groupId, groupThreadId, coordSS);

    float2 screenUV = TransformCoordSSToScreenUV(coordSS, _ScreenSize);

    float  deviceDepth = LOAD_TEXTURE2D_X(_CameraDepthTexture, coordSS).r;

    if (deviceDepth == UNITY_RAW_FAR_CLIP_VALUE)
    {
        // Sky early return;
        _SSRHitPointTexture[coordSS] = 0;
        _SSRRayInfoTexture[coordSS] = 0;
        return;
    }

    float3 N;
    float perceptualRoughness;
    GetNormalAndPerceptualRoughness(coordSS, N, perceptualRoughness);
    float oneOverPDF = 0.0f;

    if (perceptualRoughness > _SsrRoughnessFadeEnd)
    {
        // No need reflection.
        _SSRHitPointTexture[coordSS] = 0;
        _SSRRayInfoTexture[coordSS] = 0;
        return;
    }


    float3 positionWS = ComputeWorldSpacePosition(screenUV, deviceDepth, _SSR_MATRIX_I_VP); // Jittered
    float3 V = GetWorldSpaceNormalizeViewDir(positionWS);

    float3 originPosWS = positionWS;

    float ConeAngle = 0.0f;
    float3 R = reflect(-V, N); //default
#ifdef SSR_APPROX

#else
    // PBR
    if (perceptualRoughness > 0.0001f)
    {
        float2 blueNoiseRandom = 0;
        blueNoiseRandom.xy = GetSpatiotemporalBlueNoiseVec2(coordSS);
        // Bias will make the sampled points cluster more towards the top of the hemisphere.
        blueNoiseRandom.x = lerp(blueNoiseRandom.x, 0.0f, _SsrPBRBias);


        float NdotL, VdotH, NdotV;
        float3x3 localToWorld = GetLocalFrame(N);
        float roughness = PerceptualRoughnessToRoughness(perceptualRoughness);
        roughness = clamp(roughness, MIN_GGX_ROUGHNESS, MAX_GGX_ROUGHNESS);

        float3 localV, localH;
        SampleGGXVisibleNormalSphericalCaps(blueNoiseRandom, V, localToWorld, roughness, localV, localH, VdotH);
        float rayPDF = VisibleGGXPDF(localV, localH, roughness);
        float3 worldH = mul(localH, localToWorld);
        R = roughness == 0 ? R : reflect(-V, worldH);
        NdotL = dot(N, R);
        NdotV = dot(N, V);

        ConeAngle = 1.0f / max(rayPDF, 0.0001f);

        if (NdotL < 0.001f)
        {
            _SSRHitPointTexture[coordSS] = 0;
            _SSRRayInfoTexture[coordSS] = 0;
            return;
        }
    }
#endif /* SSR_PBR */

    float3 camPosWS = GetCurrentViewPosition();
    
    // Apply normal bias with the magnitude dependent on the distance from the camera.
    // Unfortunately, we only have access to the shading normal, which is less than ideal...
    positionWS = camPosWS + (positionWS - camPosWS) * (1 - 0.001 * rcp(max(dot(N, V), FLT_EPS)));
    deviceDepth = ComputeNormalizedDeviceCoordinatesWithZ(positionWS, _SSR_MATRIX_VP).z;
    bool killRay = deviceDepth == UNITY_RAW_FAR_CLIP_VALUE;

    // Ref. #1: Michal Drobot - Quadtree Displacement Mapping with Height Blending.
    // Ref. #2: Yasin Uludag  - Hi-Z Screen-Space Cone-Traced Reflections.
    // Ref. #3: Jean-Philippe Grenier - Notes On Screen Space HIZ Tracing.
    // Warning: virtually all of the code below assumes reverse Z.

    // We start tracing from the center of the current pixel, and do so up to the far plane.
    float3 rayOrigin = float3(coordSS + 0.5, deviceDepth);

    float3 reflPosWS  = positionWS + R;
    float3 reflPosNDC = ComputeNormalizedDeviceCoordinatesWithZ(reflPosWS, _SSR_MATRIX_VP); // Jittered
    float3 reflPosSS  = float3(reflPosNDC.xy * _SsrTraceScreenSize.xy, reflPosNDC.z);
    float3 rayDir     = reflPosSS - rayOrigin;
    float3 rcpRayDir  = rcp(rayDir);
    int2   rayStep    = int2(rcpRayDir.x >= 0 ? 1 : 0,
                             rcpRayDir.y >= 0 ? 1 : 0);
    float3 raySign  = float3(rcpRayDir.x >= 0 ? 1 : -1,
                             rcpRayDir.y >= 0 ? 1 : -1,
                             rcpRayDir.z >= 0 ? 1 : -1);
    bool   rayTowardsEye  =  rcpRayDir.z >= 0;
    
    // Note that we don't need to store or read the perceptualRoughness value
    // if we mark stencil during the G-Buffer pass with pixels which should receive SSR,
    // and sample the color pyramid during the lighting pass.
    killRay = killRay || (reflPosSS.z <= 0);
    killRay = killRay || (dot(N, V) <= 0);
#ifndef SSR_TRACE_TOWARDS_EYE
    killRay = killRay || rayTowardsEye;
#endif

    if (killRay)
    {
        _SSRHitPointTexture[coordSS] = 0;
        _SSRRayInfoTexture[coordSS] = 0;
        return;
    }

    // Extend and clip the end point to the frustum.
    float tMax;
    {
        // Shrink the frustum by half a texel for efficiency reasons.
        const float halfTexel = 0.5;

        float3 bounds;
        bounds.x = (rcpRayDir.x >= 0) ? _SsrTraceScreenSize.x - halfTexel : halfTexel;
        bounds.y = (rcpRayDir.y >= 0) ? _SsrTraceScreenSize.y - halfTexel : halfTexel;
        // If we do not want to intersect the skybox, it is more efficient to not trace too far.
        float maxDepth = (_SsrReflectsSky != 0) ? -0.00000024 : 0.00000024; // 2^-22
        bounds.z = (rcpRayDir.z >= 0) ? 1 : maxDepth;

        float3 dist = bounds * rcpRayDir - (rayOrigin * rcpRayDir);
        tMax = Min3(dist.x, dist.y, dist.z);
    }

    // Clamp the MIP level to give the compiler more information to optimize.
    const int maxMipLevel = min(_SsrDepthPyramidMaxMip, 14);

    // Start ray marching from the next texel to avoid self-intersections.
    float t;
    {
        // 'rayOrigin' is the exact texel center.
        float2 dist = abs(0.5 * rcpRayDir.xy);
        t = min(dist.x, dist.y);
    }

    float3 rayPos;

    int  mipLevel  = 0;
    int  iterCount = 0;
    bool hit       = false;
    bool miss      = false;
    bool belowMip0 = false; // This value is set prior to entering the cell


    while (!(hit || miss) && (t <= tMax) && (iterCount < _SsrIterLimit))
    {
        rayPos = rayOrigin + t * rayDir;

        // Ray position often ends up on the edge. To determine (and look up) the right cell,
        // we need to bias the position by a small epsilon in the direction of the ray.
        float2 sgnEdgeDist = round(rayPos.xy) - rayPos.xy;
        float2 satEdgeDist = clamp(raySign.xy * sgnEdgeDist + SSR_TRACE_EPS, 0, SSR_TRACE_EPS);
        rayPos.xy += raySign.xy * satEdgeDist;

        int2 mipCoord  = (int2)rayPos.xy >> mipLevel;
        int2 mipOffset = _DepthPyramidMipLevelOffsets[mipLevel];
        // Bounds define 4 faces of a cube:
        // 2 walls in front of the ray, and a floor and a base below it.
        float4 bounds;

        bounds.xy = (mipCoord + rayStep) << mipLevel;
        bounds.z  = LOAD_TEXTURE2D_X(_CameraDepthBufferMipChain, mipOffset + mipCoord).r;

        // We define the depth of the base as the depth value as:
        // b = DeviceDepth((1 + thickness) * LinearDepth(d))
        // b = ((f - n) * d + n * (1 - (1 + thickness))) / ((f - n) * (1 + thickness))
        // b = ((f - n) * d - n * thickness) / ((f - n) * (1 + thickness))
        // b = d / (1 + thickness) - n / (f - n) * (thickness / (1 + thickness))
        // b = d * k_s + k_b
        bounds.w = bounds.z * _SsrThicknessScale + _SsrThicknessBias;

        float4 dist      = bounds * rcpRayDir.xyzz - (rayOrigin.xyzz * rcpRayDir.xyzz);
        float  distWall  = min(dist.x, dist.y);
        float  distFloor = dist.z;
        float  distBase  = dist.w;

        // Note: 'rayPos' given by 't' can correspond to one of several depth values:
        // - above or exactly on the floor
        // - inside the floor (between the floor and the base)
        // - below the base
    #if 0
        bool belowFloor  = (raySign.z * (t - distFloor)) <  0;
        bool aboveBase   = (raySign.z * (t - distBase )) >= 0;
    #else
        bool belowFloor  = rayPos.z  < bounds.z;
        bool aboveBase   = rayPos.z >= bounds.w;
    #endif
        bool insideFloor = belowFloor && aboveBase;
        bool hitFloor    = (t <= distFloor) && (distFloor <= distWall);

        // Game rules:
        // * if the closest intersection is with the wall of the cell, switch to the coarser MIP, and advance the ray.
        // * if the closest intersection is with the heightmap below,  switch to the finer   MIP, and advance the ray.
        // * if the closest intersection is with the heightmap above,  switch to the finer   MIP, and do NOT advance the ray.
        // Victory conditions:
        // * See below. Do NOT reorder the statements!

    #ifdef SSR_TRACE_BEHIND_OBJECTS
        miss      = belowMip0 && insideFloor;
    #else
        miss      = belowMip0;
    #endif
        hit       = (mipLevel == 0) && (hitFloor || insideFloor);
        belowMip0 = (mipLevel == 0) && belowFloor;

        // 'distFloor' can be smaller than the current distance 't'.
        // We can also safely ignore 'distBase'.
        // If we hit the floor, it's always safe to jump there.
        // If we are at (mipLevel != 0) and we are below the floor, we should not move.
        t = hitFloor ? distFloor : (((mipLevel != 0) && belowFloor) ? t : distWall);
        rayPos.z = bounds.z; // Retain the depth of the potential intersection

        // Warning: both rays towards the eye, and tracing behind objects has linear
        // rather than logarithmic complexity! This is due to the fact that we only store
        // the maximum value of depth, and not the min-max.
        mipLevel += (hitFloor || belowFloor || rayTowardsEye) ? -1 : 1;
        mipLevel  = clamp(mipLevel, 0, maxMipLevel);

        // mipLevel = 0;

        iterCount++;
    }

    // Treat intersections with the sky as misses.
    miss = miss || ((_SsrReflectsSky == 0) && (rayPos.z == 0));
    hit  = hit && !miss;

    if (hit)
    {
        // Note that we are using 'rayPos' from the penultimate iteration, rather than
        // recompute it using the last value of 't', which would result in an overshoot.
        // It also needs to be precisely at the center of the pixel to avoid artifacts.
        float2 hitCoordSS = floor(rayPos.xy);
        float2 hitScreenUV = hitCoordSS * _SsrTraceScreenSize.zw + (0.5 * _SsrTraceScreenSize.zw);
        _SSRHitPointTexture[coordSS] = hitScreenUV.xy;

        float  hitDeviceZ = LOAD_TEXTURE2D_X(_CameraDepthTexture, hitCoordSS).r;
        float3 hitPosWS = ComputeWorldSpacePosition(hitScreenUV, hitDeviceZ, _SSR_MATRIX_I_VP);
        float hitDistance = length(hitPosWS - originPosWS);
        _SSRRayInfoTexture[coordSS] = float2(max(ConeAngle, HALF_MIN), 1 / hitDistance);
    }
    else
    {
        _SSRHitPointTexture[coordSS] = 0;
        _SSRRayInfoTexture[coordSS] = 0;
    }
}













#elif defined(SSR_RESOLVE)

groupshared float4  localRadianceDistance[256];
groupshared float4       localNormalDepth[256];

struct CoordData {
    float3  radiance;
    float   hitDistance;
    float3  normal;
    float   depth;
};

CoordData LoadFromGroupSharedMemory(uint2 gThreadId)
{
    uint localID = gThreadId.x + 16 * gThreadId.y;
    float4 encodedRadianceVariance = localRadianceDistance[localID];
    float4 encodedNormalDepth           = localNormalDepth[localID];

    CoordData neighborSample = (CoordData) 0;
    neighborSample.radiance = encodedRadianceVariance.xyz;
    neighborSample.hitDistance = encodedRadianceVariance.w;
    neighborSample.normal = encodedNormalDepth.xyz;
    neighborSample.depth = encodedNormalDepth.w;
    
    return neighborSample;
}

void StoreInGroupSharedMemory(uint2 gThreadId, CoordData inData)
{
    uint localID = gThreadId.x + 16 * gThreadId.y;
    localRadianceDistance[localID] = float4(inData.radiance.xyz, inData.hitDistance);
    localNormalDepth[localID] = float4(inData.normal.xyz, inData.depth);
}

float4 LoadFromGroupSharedMemoryAvgRadiance(uint2 gThreadId)
{
    uint localID = gThreadId.x + 16 * gThreadId.y;
    return localRadianceDistance[localID].xyzw;
}

void StoreInGroupSharedMemoryAvgRadiance(uint2 gThreadId, float4 radianceAndWeight)
{
    uint localID = gThreadId.x + 16 * gThreadId.y;
    localRadianceDistance[localID] = radianceAndWeight.xyzw;
}


void ResolveLoadCoordDataWithOpacity(uint2 coordSS, float4 screenSize, out float perceptualRoughness, out CoordData outData)
{
    float3 currColor = 0.0f;
    
    float2 hitScreenUV = LOAD_TEXTURE2D_X(_SSRHitPointTexture, coordSS).xy;
    if (max(hitScreenUV.x, hitScreenUV.y) != 0)
    {
        currColor = LoadUVAndSampleRadianceFromPrevColorPyramidWithOpacity(hitScreenUV);
    }
    outData.radiance = currColor;
    outData.hitDistance = 1 / max(_SSRRayInfoTexture[coordSS].y, FLT_EPS);

    GetNormalAndPerceptualRoughness(coordSS, outData.normal, perceptualRoughness);

    outData.depth = LinearEyeDepth(LOAD_TEXTURE2D_X(_CameraDepthTexture, coordSS).r, _ZBufferParams);
}

void ResolveLoadCoordData(uint2 coordSS, float4 screenSize, out float perceptualRoughness, out CoordData outData)
{
    float3 currColor = 0.0f;

    float2 hitScreenUV = LOAD_TEXTURE2D_X(_SSRHitPointTexture, coordSS).xy;
    if (max(hitScreenUV.x, hitScreenUV.y) != 0)
    {
        currColor = LoadUVAndSampleRadianceFromPrevColorPyramid(hitScreenUV);
    }
    outData.radiance = currColor;
    outData.hitDistance = 1 / max(_SSRRayInfoTexture[coordSS].y, FLT_EPS);

    GetNormalAndPerceptualRoughness(coordSS, outData.normal, perceptualRoughness);

    outData.depth = LinearEyeDepth(LOAD_TEXTURE2D_X(_CameraDepthTexture, coordSS).r, _ZBufferParams);
}

void InitializeGroupSharedMemory(uint2 dThreadId, uint2 gThreadId)
{
    uint2 offset[4] = {uint2(0, 0), uint2(8, 0), uint2(0, 8), uint2(8, 8)};

    dThreadId -= 4;

    float perceptualRoughness = 0;
    CoordData coordData[4];
    for (int i = 0; i < 4; i++)
    {
        ResolveLoadCoordDataWithOpacity(dThreadId + offset[i], _ScreenSize, perceptualRoughness, coordData[i]);
    }

    for (int j = 0; j < 4; j++)
    {
        StoreInGroupSharedMemory(gThreadId + offset[j], coordData[j]);
    }
}

// First 15 numbers of Halton(2,3) streteched to [-3,3]. Skipping the center, as we already have that in center_radiance and center_variance.
static const int kResloveSampleCount = 15;
static const int2 kResloveOffsets3x3[15] =
{
    int2( 0,  1),  
    int2(-2,  1),  
    int2( 2, -3), 
    int2(-3,  0),  
    int2( 1,  2), 
    int2(-1, -2), 
    int2( 3,  0), 
    int2(-3,  3),
    int2( 0, -3), 
    int2(-1, -1), 
    int2( 2,  1),  
    int2(-2, -2), 
    int2( 1,  0), 
    int2( 0,  2),   
    int2( 3, -1)
};

float ResloveGetEdegStoppingNormalWeight(float3 normal1, float3 normal2)
{
    return pow(max(dot(normal1, normal2), 0.0f), 512.0f);
}

float ResloveGetEdgeStoppingDepthWeight(float centerDepth, float neighDepth)
{
    return exp(-abs(centerDepth - neighDepth) * centerDepth * 4.0);
}

float ResloveGetRadianceWeight(float3 radiance1, float3 radiance2)
{
    return max(0.01, exp(-length(radiance1 - radiance2)));
}

[numthreads(8, 8, 1)]
void ScreenSpaceReflectionsResolve(uint3 dispatchThreadId : SV_DispatchThreadID, uint2 groupThreadId : SV_GroupThreadID, uint groupId : SV_GroupID)
{
    uint2 coordSS;
    InitializeDispatchThreadIdFromTileList(groupId, groupThreadId, coordSS);
    // uint2 coordSS = dispatchThreadId.xy;

    uint2 coordGroup = groupThreadId.xy;

    float perceptualRoughness;
    CoordData center;
    float3 N;

    GetNormalAndPerceptualRoughness(coordSS, N, perceptualRoughness);

    InitializeGroupSharedMemory(coordSS, coordGroup);
    GroupMemoryBarrierWithGroupSync();

    coordGroup += 4;
    center = LoadFromGroupSharedMemory(coordGroup);

    float3 radiance = center.radiance;
    float variance = 0.0f;
    if (NEED_RAYTRACED_REFLECTIONS(perceptualRoughness))
    {
        float2 screenUV = TransformCoordSSToScreenUV(coordSS, _ScreenSize);
        float  centerDeviceZ = LOAD_TEXTURE2D_X(_CameraDepthTexture, coordSS).r;
        float3 centerPosWS = ComputeWorldSpacePosition(screenUV, centerDeviceZ, _SSR_MATRIX_I_VP);
        float3 V = GetWorldSpaceNormalizeViewDir(centerPosWS);
        
        float closestHitDistance = center.hitDistance;

        float weightSum = 0.0f;
        float mean = 0.0f;
        float varianceSum = 0.0f;
        float3 radianceSum = 0.0f;

        if (IS_MIRROR_REFLECTIONS(perceptualRoughness))
        {
            weightSum = 1.0f;
            radianceSum = center.radiance;
        }
        else
        {
            float roughness = PerceptualRoughnessToRoughness(perceptualRoughness);
            roughness = clamp(roughness, MIN_GGX_ROUGHNESS, MAX_GGX_ROUGHNESS);
            float radiusScale = lerp(0.0f, 1.0f, saturate(roughness * 32));
            float rayDistScale = lerp(0.0f, 1.0f, saturate(center.hitDistance * 0.5));
            
            for (int i = 0; i < kResloveSampleCount; i++)
            {
                uint2 neighCoordSS = coordGroup + radiusScale * rayDistScale * kResloveOffsets3x3[i];

                CoordData neighData = LoadFromGroupSharedMemory(neighCoordSS);

                float weight = 1;
                weight *= ResloveGetEdegStoppingNormalWeight(center.normal, neighData.normal);
                weight *= ResloveGetEdgeStoppingDepthWeight(center.depth, neighData.depth);
                weight *= ResloveGetRadianceWeight(center.radiance, neighData.radiance);


                if (weight > .001f)
                {
                    closestHitDistance = min(closestHitDistance, neighData.hitDistance);
                    IncreaseVariance(weight, Luminance(neighData.radiance), weightSum, mean, varianceSum);
                    radianceSum += weight * neighData.radiance;
                }
            }
        }
        


        if (weightSum > 0.0f)
        {
            radianceSum /= weightSum;
            varianceSum /= weightSum;
            variance = varianceSum;
            radiance = radianceSum;
            _SSRAccumTexture[coordSS] = float4(radianceSum, varianceSum);


            float3 virtualPosWS = centerPosWS - V * closestHitDistance;
            float3 virtualPosNDC = ComputeNormalizedDeviceCoordinatesWithZ(virtualPosWS, _SSR_MATRIX_VP);
            _SSRHitDepthTexture[coordSS] = virtualPosNDC.z;
        }
    }


    GroupMemoryBarrierWithGroupSync();
    // Average radiance
    {
        coordGroup -= 4;
        float weight = 1;

        if (AnyIsInf(radiance) || AnyIsNaN(radiance) || (weight < 0.001))
        {
            weight = 0.0f;
        }
        radiance *= weight;
        StoreInGroupSharedMemoryAvgRadiance(coordGroup, float4(radiance, weight));
        GroupMemoryBarrierWithGroupSync();

        for (uint i = 2; i <= 8; i *= 2)
        {
            uint ox = coordGroup.x * i;
            uint oy = coordGroup.y * i;
            uint ix = coordGroup.x * i + i / 2;
            uint iy = coordGroup.y * i + i / 2;
            if (ix < 8 && iy < 8)
            {
                float4 radianceWeight00 = LoadFromGroupSharedMemoryAvgRadiance(uint2(ox, oy));
                float4 radianceWeight10 = LoadFromGroupSharedMemoryAvgRadiance(uint2(ox, iy));
                float4 radianceWeight01 = LoadFromGroupSharedMemoryAvgRadiance(uint2(ix, oy));
                float4 radianceWeight11 = LoadFromGroupSharedMemoryAvgRadiance(uint2(ix, iy));
                float4 sum = radianceWeight00 + radianceWeight10 + radianceWeight01 + radianceWeight11;
                StoreInGroupSharedMemoryAvgRadiance(uint2(ox, oy), sum);
            }
            GroupMemoryBarrierWithGroupSync();
        }

        if ((coordGroup.x == 0) && (coordGroup.y == 0))
        {
            float4 sum = LoadFromGroupSharedMemoryAvgRadiance(uint2(0, 0));
            sum.xyz /= max(sum.w, 0.001);
            _SSRAvgRadianceTexture[coordSS / 8] = sum.xyz;
        }
    }

}



#elif defined(SSR_ACCUMULATE)


#define _MaxFramesAccumulated 32
#define VARIANCE_REDUCTION_LERP(radiance, avgRadiance, variance) \
        (lerp(radiance, avgRadiance, saturate(variance * 5)))

groupshared float4 localRadianceVariance[256];

struct CoordData {
    float3  radiance;
    float   variance;
};

CoordData LoadFromGroupSharedMemory(uint2 gThreadId)
{
    uint localID = gThreadId.x + 16 * gThreadId.y;
    float4 encodedRadianceVariance = localRadianceVariance[localID];

    CoordData neighborSample = (CoordData) 0;
    neighborSample.radiance = encodedRadianceVariance.xyz;
    neighborSample.variance = encodedRadianceVariance.w;
    
    return neighborSample;
}

void StoreInGroupSharedMemory(uint2 gThreadId, CoordData inData)
{
    uint localID = gThreadId.x + 16 * gThreadId.y;
    localRadianceVariance[localID] = float4(inData.radiance.xyz, inData.variance);
}

void ResolveLoadCoordData(uint2 coordSS, out CoordData outData)
{
    float4 rv = _SSRAccumTexture[coordSS];
    outData.radiance = rv.xyz;
    outData.variance = rv.w;
}

void InitializeGroupSharedMemory(uint2 dThreadId, uint2 gThreadId)
{
    uint2 offset[4] = {uint2(0, 0), uint2(8, 0), uint2(0, 8), uint2(8, 8)};

    dThreadId -= 4;

    CoordData coordData[4];
    for (int i = 0; i < 4; i++)
    {
        ResolveLoadCoordData(dThreadId + offset[i], coordData[i]);
    }

    for (int j = 0; j < 4; j++)
    {
        StoreInGroupSharedMemory(gThreadId + offset[j], coordData[j]);
    }
}

struct FNeighborStatistics
{
    float3 mean;
    float3 variance;
    float3 stdDev;
    float3 minVal;
    float3 maxVal;
};

// Note: corners need to be first for GetNeighborStatistics
static const int2 kOffsets3x3[8] =
{
	int2(-1, -1),
	int2( 1, -1),
	int2(-1,  1),
	int2( 1,  1),
	int2( 0, -1),
	int2(-1,  0),
	int2( 1,  0),
	int2( 0,  1),
};
FNeighborStatistics GetNeighborStatistics(
    uint2 coordGroup, 
    uint2 MinScreenCoord, 
    uint2 MaxScreenCoord,
    float3 centerLighting,
    float3 avgRadiance)
{
    FNeighborStatistics result = (FNeighborStatistics)0;

    int count = 1;
    float3 M1 = centerLighting;
    float3 M2 = (float3)0;

    result.minVal = centerLighting;
    result.maxVal = centerLighting;

    for(uint neighborId = 0; neighborId < 8; neighborId++)
    {
        int2 offset = kOffsets3x3[neighborId];
        uint2 neighCoordGroup = coordGroup + offset;
        neighCoordGroup = clamp(neighCoordGroup, MinScreenCoord, MaxScreenCoord);
        
        CoordData neighData;
        neighData = LoadFromGroupSharedMemory(neighCoordGroup);
        neighData.radiance = VARIANCE_REDUCTION_LERP(neighData.radiance, avgRadiance, neighData.variance);
        {
            result.minVal = min(result.minVal, neighData.radiance);
            result.maxVal = max(result.maxVal, neighData.radiance);

            // Welford's online algorithm for variance.
            // More numerically stable than accumulating squares.
            // https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance
            count += 1;
            float3 delta1 = neighData.radiance - M1;
            M1 += delta1 / count;
            float3 delta2 = neighData.radiance - M1;
            M2 += delta1 * delta2;
        }
    }

    result.mean = M1;
    result.variance = M2 / (count - 1 + FLT_EPS);
    result.stdDev = sqrt(result.variance);

    return result;
}


struct FBilinear
{
    float2 origin;
    float2 weights;
};

FBilinear GetBilinearFilter(float2 uv, float2 textureSize)
{
    FBilinear result;
    result.origin = floor(uv * textureSize - 0.5f);
    result.weights = frac(uv * textureSize - 0.5f);
    return result;
}


struct FGatherUV
{
    float2 uv00;
    float2 uv10;
    float2 uv11;
    float2 uv01;
};

FGatherUV GetGatherUV(FBilinear In, float2 texelSize)
{
    FGatherUV o;
    o.uv00 = (In.origin + .5f) * texelSize;
    o.uv10 = o.uv00 + float2(texelSize.x, 0);
    o.uv01 = o.uv00 + float2(0, texelSize.y);
    o.uv11 = o.uv00 + texelSize;
    return o;
}

float4 GetBilinearCustomWeights(FBilinear F, float4 CustomWeights)
{
    float4 weights;
    weights.x = (1.0f - F.weights.x) * (1.0f - F.weights.y);
    weights.y = F.weights.x * (1.0f - F.weights.y);
    weights.z = (1.0f - F.weights.x) * F.weights.y;
    weights.w = F.weights.x * F.weights.y;
    return weights * CustomWeights;
}

float3 WeightedAverage(float3 V00, float3 V10,  float3 V01,  float3 V11, float4 weights)
{
    float3 result = V00 * weights.x + V10 * weights.y + V01 * weights.z + V11 * weights.w;
    return result / max(dot(weights, 1), 0.00001f);
}

float WeightedAverage(float4 V, float4 weights)
{    
    return dot(V, weights) / max(dot(weights, 1), .00001f);
}

struct FSpecularIndirectHistory
{
    float3 specularIndirect;
    float4 weights;
};

// Fetch the specular indirect history
// * Returns the filtered specular indirect value (average only valid history sample
// * Returns the weights of each indirect samples (valid/invalid)
FSpecularIndirectHistory FetchHistory(TEXTURE2D_X(historyTexture), FBilinear inBilinear, uint InBSDFIndex, float4 screenSize, float4 inWeights = float4(1,1,1,1))
{
    FSpecularIndirectHistory o;
    o.weights = GetBilinearCustomWeights(inBilinear, inWeights);
    FGatherUV InHistoryBilinear = GetGatherUV(inBilinear, screenSize.zw);

    float4 historySpecularIndirect00 = SAMPLE_TEXTURE2D_X_LOD(historyTexture, ssr_point_clamp_sampler, InHistoryBilinear.uv00, 0).xyzw;
    float4 historySpecularIndirect10 = SAMPLE_TEXTURE2D_X_LOD(historyTexture, ssr_point_clamp_sampler, InHistoryBilinear.uv10, 0).xyzw;
    float4 historySpecularIndirect01 = SAMPLE_TEXTURE2D_X_LOD(historyTexture, ssr_point_clamp_sampler, InHistoryBilinear.uv01, 0).xyzw;
    float4 historySpecularIndirect11 = SAMPLE_TEXTURE2D_X_LOD(historyTexture, ssr_point_clamp_sampler, InHistoryBilinear.uv11, 0).xyzw;

    o.weights.x *= historySpecularIndirect00.w > 0 ? 1.0f : 0.0f;
    o.weights.y *= historySpecularIndirect10.w > 0 ? 1.0f : 0.0f;
    o.weights.z *= historySpecularIndirect01.w > 0 ? 1.0f : 0.0f;
    o.weights.w *= historySpecularIndirect11.w > 0 ? 1.0f : 0.0f;

    o.specularIndirect = WeightedAverage(historySpecularIndirect00.xyz, historySpecularIndirect10.xyz, historySpecularIndirect01.xyz, historySpecularIndirect11.xyz, o.weights);
    return o;
}

[numthreads(8, 8, 1)]
void ScreenSpaceReflectionsAccumulate(uint3 dispatchThreadId : SV_DispatchThreadID, uint2 groupThreadId : SV_GroupThreadID, uint groupId : SV_GroupID)
{
    uint2 coordSS;
    InitializeDispatchThreadIdFromTileList(groupId, groupThreadId, coordSS);
    // uint2 coordSS = dispatchThreadId.xy;

    uint2 coordGroup = groupThreadId.xy;
    float2 screenUV = TransformCoordSSToScreenUV(coordSS, _ScreenSize);

    float3 N;
    float perceptualRoughness;
    GetNormalAndPerceptualRoughness(coordSS, N, perceptualRoughness);

    CoordData center;
    InitializeGroupSharedMemory(coordSS, coordGroup);
    GroupMemoryBarrierWithGroupSync();

    coordGroup += 4;
    center = LoadFromGroupSharedMemory(coordGroup);
    
    
    if (NEED_RAYTRACED_REFLECTIONS(perceptualRoughness))
    {
        // Compute the actual roughness
        float roughness = PerceptualRoughnessToRoughness(perceptualRoughness);
        roughness = clamp(roughness, MIN_GGX_ROUGHNESS, MAX_GGX_ROUGHNESS);
        float roughnessReductionFactor = 1 - exp(-roughness * 100.0f);

        float3 avgRadiance = SAMPLE_TEXTURE2D_X_LOD(_SSRAvgRadianceTexture, ssr_bilinear_clamp_sampler, screenUV, 0).xyz;

        float3 currColor = VARIANCE_REDUCTION_LERP(center.radiance, avgRadiance, center.variance);
        float reflectionHitDeviceZ = _SSRHitDepthTexture[coordSS].x;
        float deviceDepth = LOAD_TEXTURE2D_X(_CameraDepthTexture, coordSS).r;
        float2 motionVector = LoadMotionVectorOffset(coordSS);

        float3 prevScreenPosFromVirtualHit = GetHistoryScreenPos(screenUV, deviceDepth, reflectionHitDeviceZ, motionVector, _SSR_MATRIX_CLIP_TO_PREV_CLIP);
        float3 prevScreenPosFromSceneDepth = GetHistoryScreenPos(screenUV, deviceDepth, deviceDepth, motionVector, _SSR_MATRIX_CLIP_TO_PREV_CLIP);

        // HistoryFrameTexture (_SsrAccumPrev and _SSRPrevNumFramesAccumTexture)
        // CoordSS may not coverage RT completely, screen uv may lower than 1, when viewport changed.
        // This situation is similar to ColorPyramid.
        prevScreenPosFromVirtualHit.xy *= _ColorPyramidUvScaleAndLimitPrevFrame.xy;
        prevScreenPosFromSceneDepth.xy *= _ColorPyramidUvScaleAndLimitPrevFrame.xy;

        FBilinear bilinearVirtualHit = GetBilinearFilter(prevScreenPosFromVirtualHit.xy, _HistoryFrameRTSize.xy);
        FBilinear bilinearSceneDepth = GetBilinearFilter(prevScreenPosFromSceneDepth.xy, _HistoryFrameRTSize.xy);

        FSpecularIndirectHistory historyFromVirtualHit = FetchHistory(_SsrAccumPrev, bilinearVirtualHit, 0, _HistoryFrameRTSize.xyzw);
        FSpecularIndirectHistory historyFromSceneDepth = FetchHistory(_SsrAccumPrev, bilinearSceneDepth, 0, _HistoryFrameRTSize.xyzw);

        FNeighborStatistics neighborhood = GetNeighborStatistics(coordGroup, uint2(0,0), _HistoryFrameRTSize.xy, currColor, avgRadiance);


        float InvalidHistoryErrorThreshold = 1e6;
        float ErrorFromReflectHit = (any(prevScreenPosFromVirtualHit.xy >= 0) && any(prevScreenPosFromVirtualHit.xy <= 1)) ? abs(Luminance(historyFromVirtualHit.specularIndirect) - Luminance(neighborhood.mean)) : InvalidHistoryErrorThreshold;
        float ErrorFromSceneDepth = (any(prevScreenPosFromSceneDepth.xy >= 0) && any(prevScreenPosFromSceneDepth.xy <= 1)) ? abs(Luminance(historyFromSceneDepth.specularIndirect) - Luminance(neighborhood.mean)) : InvalidHistoryErrorThreshold;

        float3 historySpecularIndirect = ErrorFromReflectHit < ErrorFromSceneDepth
            ? historyFromVirtualHit.specularIndirect 
            : historyFromSceneDepth.specularIndirect;

        neighborhood.stdDev = (neighborhood.stdDev + length(neighborhood.mean.xyz - avgRadiance)) * 1.0f;
        neighborhood.mean = lerp(neighborhood.mean.xyz, avgRadiance, 0.2f * roughnessReductionFactor);
        float3 historyClampMin = neighborhood.mean - neighborhood.stdDev;
        float3 historyClampMax = neighborhood.mean + neighborhood.stdDev;

        historyClampMin = max(0, historyClampMin);
        historySpecularIndirect = clamp(historySpecularIndirect, neighborhood.minVal, historyClampMax);




        float3 historyScreenUV = ErrorFromReflectHit < ErrorFromSceneDepth
            ? prevScreenPosFromVirtualHit
            : prevScreenPosFromSceneDepth;

        // Sample neighbor frames num
        float historyFramesNum = SAMPLE_TEXTURE2D_X_LOD(_SSRPrevNumFramesAccumTexture, ssr_point_clamp_sampler, historyScreenUV.xy, 0).x;
        float maxSamplesNum = max(8.0f, _MaxFramesAccumulated * roughnessReductionFactor) * _SsrAccumulationAmount;
        historyFramesNum *= maxSamplesNum;
        historyFramesNum = min(historyFramesNum + 1.0f, maxSamplesNum);
        float accumulatedFramesNum = (all(historyScreenUV.xy > 0) && all(historyScreenUV.xy < 1)) ? historyFramesNum : 0;

        // Temporal accumulate
        float temporalWeight = 1.0f / max(1.0f, accumulatedFramesNum);
        float3 result = lerp(historySpecularIndirect, currColor, temporalWeight);

        // Valid result
        uint3 intCol = asuint(result.rgb);
        bool  isPosFin = Max3(intCol.r, intCol.g, intCol.b) < 0x7F800000;
        result.rgb = isPosFin ? result.rgb : 0;
        bool bResultValid = all(result != 0);

        // RoughnessFade
        float roughnessFade = PerceptualRoughnessFade(perceptualRoughness, _SsrRoughnessFadeRcpLength, _SsrRoughnessFadeEndTimesRcpLength);

        // Write texture
        _SsrLightingTexture[coordSS] = float4(result * roughnessFade, Luminance(neighborhood.variance));
        _SSRAccumTexture[coordSS] = float4(result, bResultValid);
        _SSRNumFramesAccumTexture[coordSS] = accumulatedFramesNum / maxSamplesNum;
    }

}

#endif

#undef MIN_GGX_ROUGHNESS
#undef MAX_GGX_ROUGHNESS